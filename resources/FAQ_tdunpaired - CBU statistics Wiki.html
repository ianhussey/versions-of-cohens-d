<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<!-- saved from url=(0058)https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired -->
<html><input type="hidden" id="__yoroi_connector_api_injected_type" value="prod"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- BEGIN:mathml_header-->
    </head><body lang="en" dir="ltr"><object id="mathplayer" style="height: 0px;" classid="clsid:32F66A20-7614-11D4-BD11-00104BD3F987">
    </object>
    <!--?import namespace="mml" implementation="#mathplayer"?-->
    <!-- END:mathml_header-->
    <!-- BEGIN:asciimathml-->
    <script type="text/javascript" src="./FAQ_tdunpaired - CBU statistics Wiki_files/asciimathml.js"></script>
    <!-- END:asciimathml-->
    
    <!-- Google tag (gtag.js) -->
    <script async="" src="./FAQ_tdunpaired - CBU statistics Wiki_files/js"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-G6QPG3PC2Z');
    </script>
    
<meta name="robots" content="index,nofollow">

<title>FAQ/tdunpaired - CBU statistics Wiki</title>
<script type="text/javascript" src="./FAQ_tdunpaired - CBU statistics Wiki_files/common.js"></script>

<script type="text/javascript">
<!--
var search_hint = "Search";
//-->
</script>


<link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="./FAQ_tdunpaired - CBU statistics Wiki_files/common.css">
<link rel="stylesheet" type="text/css" charset="utf-8" media="screen" href="./FAQ_tdunpaired - CBU statistics Wiki_files/screen.css">
<link rel="stylesheet" type="text/css" charset="utf-8" media="print" href="./FAQ_tdunpaired - CBU statistics Wiki_files/print.css">
<link rel="stylesheet" type="text/css" charset="utf-8" media="projection" href="./FAQ_tdunpaired - CBU statistics Wiki_files/projection.css">

<!-- css only for MS IE6/IE7 browsers -->
<!--[if lt IE 8]>
   <link rel="stylesheet" type="text/css" charset="utf-8" media="all" href="/basewiki/moin_static1910/moniker_cbu/css/msie.css">
<![endif]-->


<link rel="alternate" title="CBU statistics Wiki: FAQ/tdunpaired" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?diffs=1&amp;show_att=1&amp;action=rss_rc&amp;unique=0&amp;page=FAQ%2Ftdunpaired&amp;ddiffs=1" type="application/rss+xml">

<script type="text/javascript" src="./FAQ_tdunpaired - CBU statistics Wiki_files/actionmenuoptions.js"></script>

<link rel="Start" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/CbuStatistics">
<link rel="Alternate" title="Wiki Markup" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=raw">
<link rel="Alternate" media="print" title="Print View" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=print">
<link rel="Up" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ">
<link rel="Search" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FindPage">
<link rel="Index" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/TitleIndex">
<link rel="Glossary" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/WordIndex">
<link rel="Help" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/HelpOnFormatting">



<div id="wrapper">

<div id="header"><div id="logo"><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/CbuStatistics"><img src="./FAQ_tdunpaired - CBU statistics Wiki_files/CBSU6.png" alt="CBU Logo"></a></div>
<h1 class="wikititle">MRC CBU Wiki</h1>

<div id="username">welcome: <a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=login" id="login" rel="nofollow">please sign in</a></div>
</div><!-- header -->


<div id="sidebar">
<div class="sidepanel"><h1>Quick Links</h1>
		<ul id="navibar">
		<li class="wikilink"><a href="http://www.mrc-cbu.cam.ac.uk/">CBSU Home</a></li><li class="wikilink"><a href="http://intranet.mrc-cbu.cam.ac.uk/">CBSU Intranet</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/methods/WikiOverview">Wiki Overview</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/imaging/CbuImaging">Imaging Wiki</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/meg/CbuMeg">MEG Wiki</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/methods/">Methods Wiki</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/statswiki">Statistics wiki</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/methods/NavigateOurWiki">Navigate Wikis</a></li><li class="wikilink"><a href="http://imaging.mrc-cbu.cam.ac.uk/methods/cookies">Cookies and Privacy</a></li><li class="wikilink"><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FindPage">FindPage</a></li><li class="wikilink"><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/RecentChanges">RecentChanges</a></li><li class="wikilink"><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/HelpContents">HelpContents</a></li>
		</ul>
</div>
<div class="sidepanel"><h1>Search Wiki</h1>
<form id="searchform" method="get" action="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired">
<div>
<input type="hidden" name="action" value="fullsearch">
<input type="hidden" name="context" value="180">

<input id="searchinput" type="text" name="value" value="" onfocus="searchFocus(this)" onblur="searchBlur(this)" onkeyup="searchChange(this)" onchange="searchChange(this)" alt="this" class="disabled">
    <div id="searchbuttons">
    <input id="titlesearch" name="titlesearch" type="submit" value="Titles" alt="Search Titles" disabled="">
<input id="fullsearch" name="fullsearch" type="submit" value="Text" alt="Search Full Text" disabled="">
</div>
</div>
</form>
<script type="text/javascript">
// Initialize search form
// var f = document.getElementById('searchform');
// f.getElementsByTagName('label')[0].style.display = 'none';
var e = document.getElementById('searchinput');
e.value = "";
searchChange(e);
searchBlur(e);
</script>
</div>

<div class="sidepanel"><h1>Page Tools</h1><ul class="editbar"><li><span class="disabled">Page Locked</span></li><li class="toggleCommentsButton" style="display:none;"><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired#" class="nbcomment" onclick="toggleComments();return false;">Comments</a></li><li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=info" rel="nofollow">page history</a></li><li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=AttachFile" rel="nofollow">upload &amp; manage files</a></li><li>
<div class="togglelink" id="togglelink" onclick="toggleMenu(&#39;menu1&#39;)">[ more options ]</div>
<div id="menu1">
<ul>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=raw">Raw Text</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=print">Print View</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=RenderAsDocbook">Render as Docbook</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=refresh">Delete Cache</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=SpellCheck">Check Spelling</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=LikePages">Like Pages</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=LocalSiteMap">Local Site Map</a></li>
<li class="disabled">Rename Page</li>
<li class="disabled">Delete Page</li>
<li class="disabled">Subscribe User</li>
<li class="disabled">Remove Spam</li>
<li class="disabled">revert to this revision</li>
<li class="disabled">Package Pages</li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=SyncPages">Sync Pages</a></li>
<li class="disabled"></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=Load">Load</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=Save">Save</a></li>
<li><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired?action=SlideShow">SlideShow</a></li>
</ul>
</div>
</li></ul>
</div>
</div>


<div id="page" lang="en" dir="ltr">

<span id="pagelocation">location: <span class="pagepath"><a href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ">FAQ</a></span><span class="sep"> / </span><a class="backlink" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/tdunpaired" rel="nofollow">tdunpaired</a></span><div dir="ltr" id="content" lang="en"><span class="anchor" id="top"></span>
<span class="anchor" id="line-1"></span><p class="line874">Taken from Jake Westfall's comments on choice of Cohen's d  <span class="anchor" id="line-2"></span><a class="http" href="http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/">here.</a> <span class="anchor" id="line-3"></span><span class="anchor" id="line-4"></span></p><p class="line867">
</p><h1 id="Five_different_.2BIBw-Cohen.2BIBk-s_d.2BIB0_statistics_for_within-subject_designs">Five different “Cohen’s d” statistics for within-subject designs</h1>
<span class="anchor" id="line-5"></span><span class="anchor" id="line-6"></span><p class="line874">Jeff Rouder poses an “effect size puzzler” where the puzzle is simply to compute a standardized effect size for a simulated dataset where subjects make 50 responses in each of 2 conditions. He offers a sweatshirt prize (???) to anyone who can do so “correctly.” <span class="anchor" id="line-7"></span><span class="anchor" id="line-8"></span></p><p class="line874">(Update: Jeff posted his answer to the effect size puzzler here.) <span class="anchor" id="line-9"></span><span class="anchor" id="line-10"></span></p><p class="line874">As it happens, I’ve been meaning for a while to write a blog post on issues with computing d-like effect sizes (or other standardized effect sizes) for within-subject designs, so now seems like a good time to finally hammer out the post. <span class="anchor" id="line-11"></span><span class="anchor" id="line-12"></span></p><p class="line874">Jeff didn’t actually say anything to restrict us to standardized mean difference type measures (as opposed to, say, variance explained type measures), and we can only guess whether the “correct” effect size he has in mind is a d-like measure or an R^2-like measure or what. But here I’ll focus on d-like measures, which are perhaps the most popular for studies with categorical predictors, and offer plenty of complications that I think are often under-appreciated (and it seems Jeff would agree). <span class="anchor" id="line-13"></span><span class="anchor" id="line-14"></span></p><p class="line874">What I’ll show here is that there are at least 5 different and non-equivalent ways that people might compute a d-like effect size (which they would invariably simply call “Cohen’s d”) for Jeff’s dataset, and the resulting effect sizes range from about 0.25 to 1.91. I’ll compare and contrast these procedures and ultimately choose one that I think is the least crazy, if you must compute a standardized effect size (more on that later). When I read a paper that reports “Cohen’s d” for a within-subject design, I usually have no idea which of these 5 procedures the authors actually applied unless I try to reproduce the effect size myself from some of the descriptives in the paper, which is often not possible. <span class="anchor" id="line-15"></span><span class="anchor" id="line-16"></span></p><p class="line874">Jeff’s dataset can be downloaded here.  Here’s some code to load it into R, examine it, print the two conditions means, and save the mean difference as <span class="anchor" id="line-17"></span>md: <span class="anchor" id="line-18"></span><span class="anchor" id="line-19"></span></p><p class="line867"><span class="anchor" id="line-20"></span><span class="anchor" id="line-21"></span><span class="anchor" id="line-22"></span><span class="anchor" id="line-23"></span><span class="anchor" id="line-24"></span><span class="anchor" id="line-25"></span><span class="anchor" id="line-26"></span><span class="anchor" id="line-27"></span><span class="anchor" id="line-28"></span><span class="anchor" id="line-29"></span><span class="anchor" id="line-30"></span><span class="anchor" id="line-31"></span><span class="anchor" id="line-32"></span><span class="anchor" id="line-33"></span><span class="anchor" id="line-34"></span><span class="anchor" id="line-35"></span><span class="anchor" id="line-36"></span></p><pre><span class="anchor" id="line-1"></span>1 dat &lt;- read.table("http://pcl.missouri.edu/exp/effectSizePuzzler.txt", header=TRUE) 
<span class="anchor" id="line-2"></span>2 
<span class="anchor" id="line-3"></span> 
<span class="anchor" id="line-4"></span>3 str(dat) 
<span class="anchor" id="line-5"></span>4 # 'data.frame':       2500 obs. of  3 variables: 
<span class="anchor" id="line-6"></span>5 #  $ id  : int  1 1 1 1 1 1 1 1 1 1 ... 
<span class="anchor" id="line-7"></span>6 #  $ cond: int  1 1 1 1 1 1 1 1 1 1 ... 
<span class="anchor" id="line-8"></span>7 #  $ rt  : num  0.56 0.93 0.795 0.615 1.028 ... 
<span class="anchor" id="line-9"></span>8 
<span class="anchor" id="line-10"></span> 
<span class="anchor" id="line-11"></span>9 (means &lt;- with(dat, tapply(rt, cond, mean))) 
<span class="anchor" id="line-12"></span>10 #         1         2  
<span class="anchor" id="line-13"></span>11 # 0.8322560 0.8845544  
<span class="anchor" id="line-14"></span>12 
<span class="anchor" id="line-15"></span> 
<span class="anchor" id="line-16"></span>13 md &lt;- diff(means) </pre><span class="anchor" id="line-37"></span><span class="anchor" id="line-38"></span><p class="line862">view raw esPuzzlerData.R hosted with ❤ by <a class="nonexistent" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/GitHub">GitHub</a>  <span class="anchor" id="line-39"></span><span class="anchor" id="line-40"></span></p><p class="line874">d: Classical Cohen’s d <span class="anchor" id="line-41"></span><span class="anchor" id="line-42"></span></p><p class="line874">This is essentially a straightforward application of the formula provided by Cohen himself: <span class="anchor" id="line-43"></span><span class="anchor" id="line-44"></span></p><p class="line874">d=(M_1-M_2) /sigma <span class="anchor" id="line-45"></span><span class="anchor" id="line-46"></span></p><p class="line874">The numerator is the mean difference. Cohen never actually gives a clear, unambiguous definition of sigma in the denominator, but it is usually taken to be the pooled standard deviation, that is, the square root of the average variance in each condition (assuming equal sample sizes in both conditions). In R code: <span class="anchor" id="line-47"></span><span class="anchor" id="line-48"></span></p><p class="line867"><span class="anchor" id="line-49"></span><span class="anchor" id="line-50"></span><span class="anchor" id="line-51"></span></p><pre><span class="anchor" id="line-1-1"></span>(d &lt;- md / with(dat, sqrt(mean(tapply(rt, cond, var)))))
<span class="anchor" id="line-2-1"></span># 0.2497971</pre><span class="anchor" id="line-52"></span><span class="anchor" id="line-53"></span><p class="line874">The crucial thing to recognize about applying the classical Cohen’s d is that it deliberately ignores information about the design of the study. That is, you compute d the same way whether you are dealing with a between-subjects, within-subjects, or mixed design. Basically, in computing d, you always treat the data as if it came from a simple two-independent-groups design. I don’t want to get bogged down by a discussion of why that is a good thing at this point in the post—I’ll get into that later on. For now I just note that, with this effect size, within-subject designs tend to be powerful not because they lead to larger effect sizes—if anything, the reverse is probably true, in that people elect to use within-subject designs when Cohen’s d is particularly small, for example in many reaction time studies—but rather because they allow us to efficiently detect smaller effect sizes due to removing irrelevant sources of variation from the denominator of the test statistic. <span class="anchor" id="line-54"></span><span class="anchor" id="line-55"></span></p><p class="line874">da: Cohen’s d after averaging over replicates <span class="anchor" id="line-56"></span><span class="anchor" id="line-57"></span></p><p class="line874">For this next way of computing a d-like effect size, the section heading pretty much says it all. In Jeff’s dataset, each participant makes a total of 100 responses, 50 in each condition. The computation of d_a proceeds by first averaging over the 50 responses in each subject-by-condition cell of the experiment, so that each subject’s data is reduced to 2 means, and then applying the classical d formula to this aggregated data. In R code: <span class="anchor" id="line-58"></span>sub_means &lt;- with(dat, tapply(rt, list(id, cond), mean)) <span class="anchor" id="line-59"></span><span class="anchor" id="line-60"></span></p><p class="line867"><span class="anchor" id="line-61"></span><span class="anchor" id="line-62"></span><span class="anchor" id="line-63"></span></p><pre><span class="anchor" id="line-1-2"></span>(d_a &lt;- md / sqrt(mean(diag(var(sub_means)))))
<span class="anchor" id="line-2-2"></span># 0.8357347</pre><span class="anchor" id="line-64"></span><span class="anchor" id="line-65"></span><p class="line874">Richard Morey blogged about some weird things that can happen when you compute a standardized effect size this way. The basic issue is that, unlike classical Cohen’s d, d_a does not ignore all the design information: d_a will tend to be larger when there are more replicates, that is, when each subject responds more frequently in each condition. <span class="anchor" id="line-66"></span><span class="anchor" id="line-67"></span></p><p class="line874">dz: Standardized difference scores <span class="anchor" id="line-68"></span><span class="anchor" id="line-69"></span></p><p class="line874">A third way to compute a d-like effect size is to reduce each subject’s data to a single difference score—the mean difference between their responses in each condition—and then use the standard deviation of these difference scores as the denominator of d. Cohen actually discusses this statistic in his power analysis textbook (Cohen, 1988, p. 48), where he carefully distinguishes it from the classical Cohen’s d by calling it d_z. In R, we can compute this as: <span class="anchor" id="line-70"></span><span class="anchor" id="line-71"></span></p><p class="line867"><span class="anchor" id="line-72"></span><span class="anchor" id="line-73"></span><span class="anchor" id="line-74"></span></p><pre><span class="anchor" id="line-1-3"></span>(d_z &lt;- md / sd(sub_means[,2] - sub_means[,1]))
<span class="anchor" id="line-2-3"></span># 1.353713</pre><span class="anchor" id="line-75"></span><span class="anchor" id="line-76"></span><p class="line874">There is a straightforward relationship between d_z and the test statistic: t_w = d_z\sqrt{n}, where t_w is the paired-samples t-statistic from a within-subjects design and n is the number of subjects. One might regard this as a virtue of d_z. I will argue below that I don’t think it’s a good idea to use d_z. <span class="anchor" id="line-77"></span><span class="anchor" id="line-78"></span></p><p class="line874">dt: Naive conversion from t-statistic <span class="anchor" id="line-79"></span><span class="anchor" id="line-80"></span></p><p class="line874">In a simple two-independent groups design, one can compute the classical Cohen’s d from the t-statistic using <span class="anchor" id="line-81"></span><span class="anchor" id="line-82"></span></p><p class="line867"><span class="anchor" id="line-83"></span><span class="anchor" id="line-84"></span></p><pre><span class="anchor" id="line-1-4"></span>d=t_b Sqrt[2/n] </pre><span class="anchor" id="line-85"></span><span class="anchor" id="line-86"></span><p class="line874">where t_b is the independent-samples t-statistic for a between-subjects design and n is the number of subjects per group. Many, many authors over the years have incorrectly assumed that this same conversion formula will yield sensible results for other designs as well, such as in the present within-subjects case. Dunlap et al. (1996) wrote a whole paper about this issue. One might suppose that applying this conversion formula to t_w will yield d_z, but we can see that this is not the case by solving the equation given in the previous section for d_z, which yields d_z=\frac{t_w}{\sqrt{n}}. In other words, naive application of the between-subjects conversion formula yields an effect size that is off by a factor of \sqrt{2}. <span class="anchor" id="line-87"></span><span class="anchor" id="line-88"></span></p><p class="line874">To compute d_t in R: <span class="anchor" id="line-89"></span><span class="anchor" id="line-90"></span></p><p class="line867"><span class="anchor" id="line-91"></span><span class="anchor" id="line-92"></span><span class="anchor" id="line-93"></span><span class="anchor" id="line-94"></span></p><pre><span class="anchor" id="line-1-5"></span>t_stat &lt;- t.test(sub_means[,2] - sub_means[,1])$statistic
<span class="anchor" id="line-2-4"></span>(d_t &lt;- t_stat*sqrt(2/nrow(sub_means)))
<span class="anchor" id="line-3-1"></span># 1.914439</pre><span class="anchor" id="line-95"></span><span class="anchor" id="line-96"></span><p class="line874">dr: Residual standard deviation in the denominator <span class="anchor" id="line-97"></span><span class="anchor" id="line-98"></span></p><p class="line874">Finally, one can compute a d-like effect size for this within-subject design by assuming that the \sigma in the classical Cohen’s d formula refers to the standard deviation of the residuals. This is the approach taken in Rouder et al. (2012) on Bayes factors for ANOVA designs. In between-subjects designs where each subject contributes a single response, this is equivalent to classical Cohen’s d. But it differs from classical Cohen’s d in designs where subjects contribute multiple responses. <span class="anchor" id="line-99"></span><span class="anchor" id="line-100"></span></p><p class="line874">To compute d_r in R, we need an estimate of the residual standard deviation. Two ways to obtain this are from a full ANOVA decomposition of the data or by fitting a linear mixed model to the data. Here I do it the mixed model way: <span class="anchor" id="line-101"></span><span class="anchor" id="line-102"></span></p><p class="line867"><span class="anchor" id="line-103"></span><span class="anchor" id="line-104"></span><span class="anchor" id="line-105"></span><span class="anchor" id="line-106"></span><span class="anchor" id="line-107"></span><span class="anchor" id="line-108"></span><span class="anchor" id="line-109"></span><span class="anchor" id="line-110"></span><span class="anchor" id="line-111"></span><span class="anchor" id="line-112"></span><span class="anchor" id="line-113"></span><span class="anchor" id="line-114"></span><span class="anchor" id="line-115"></span><span class="anchor" id="line-116"></span><span class="anchor" id="line-117"></span><span class="anchor" id="line-118"></span></p><pre><span class="anchor" id="line-1-6"></span>options(contrasts=c("contr.helmert","contr.poly"))
<span class="anchor" id="line-2-5"></span>library("lme4")
<span class="anchor" id="line-3-2"></span>mod &lt;- lmer(rt ~ cond + (cond||id), data=dat)
<span class="anchor" id="line-4-1"></span>summary(mod)
<span class="anchor" id="line-5-1"></span># Random effects:
<span class="anchor" id="line-6-1"></span>#  Groups   Name        Variance  Std.Dev.
<span class="anchor" id="line-7-1"></span>#  id       (Intercept) 0.0026469 0.05145 
<span class="anchor" id="line-8-1"></span>#  id.1     cond        0.0001887 0.01374 
<span class="anchor" id="line-9-1"></span>#  Residual             0.0407839 0.20195 
<span class="anchor" id="line-10-1"></span># Number of obs: 2500, groups:  id, 25
<span class="anchor" id="line-11-1"></span># 
<span class="anchor" id="line-12-1"></span># Fixed effects:
<span class="anchor" id="line-13-1"></span>#             Estimate Std. Error t value
<span class="anchor" id="line-14-1"></span># (Intercept) 0.779958   0.016402   47.55
<span class="anchor" id="line-15-1"></span># cond        0.052298   0.008532    6.13</pre><span class="anchor" id="line-119"></span><span class="anchor" id="line-120"></span><p class="line874">The residual standard deviation is estimated as 0.20195, which gives us d_r = 0.259. It turns out that, for this dataset, this is quite close to the classical Cohen’s d, which was 0.25. Basically, classical Cohen’s d is equivalent to using the square root of the sum of all the variance components in the denominator1,2, rather than just the square root of the residual variance as d_r uses. For this simulated dataset, the two additional variance components (intercepts and slopes varying randomly across subjects) are quite small compared to the residual variance, so adding them to the denominator of the effect size does not change it much. But the important thing to note is that for other datasets, it is possible that d and d_r could differ dramatically. <span class="anchor" id="line-121"></span><span class="anchor" id="line-122"></span></p><p class="line874">So which one should I compute? <span class="anchor" id="line-123"></span><span class="anchor" id="line-124"></span></p><p class="line874">Contrary to Jeff, I don’t really think there’s a “correct” answer here. (Well, maybe we can say that it’s hard to see any justification for computing d_t.) As I put it in the comments to an earlier blog post: <span class="anchor" id="line-125"></span><span class="anchor" id="line-126"></span></p><p class="line874">Basically all standardized effect sizes are just made-up quantities that we use because we think they have more sensible and desirable properties for certain purposes than the unstandardized effects. For a given unstandardized effect, there are any number of ways we could “standardize” that effect, and the only real basis we have for choosing among these different effect size definitions is in choosing the one that has the most sensible derivation and the most desirable properties relative to other candidates. <span class="anchor" id="line-127"></span><span class="anchor" id="line-128"></span></p><p class="line867"><em>I believe that classical Cohen’s d is the option that makes the most sense among these candidates</em>. Indeed, in my dissertation I proposed a general definition of d that I claim is the most natural generalization of Cohen’s d to the class of general ANOVA designs, and I considered it very important that it reduce to the classical Cohen’s d for datasets like Jeff’s. My reasoning is this. One of the primary motivations for using standardized effect sizes at all is so that we can try to meaningfully compare effects from different studies, including studies that might use different designs. But all of the effect size candidates other than classical Cohen’s d are affected by the experimental design; that is, the “same” effect will have a larger or smaller effect size based on whether we used a between- or within-subjects design, how many responses we required each subject to make, and so on. Precisely because of this, we cannot meaningfully compare these effect sizes across different experimental designs. Because classical Cohen’s d deliberately ignores design information, it is at least in-principle possible to compare effect sizes across different designs. Morris and <a class="nonexistent" href="https://imaging.mrc-cbu.cam.ac.uk/statswiki/DeShon">DeShon</a> (2002) is a nice paper that talks about these issues. Bakeman (2005) also has some great discussion of essentially this same issue, focused instead on “variance explained”-type effect sizes. <span class="anchor" id="line-129"></span><span class="anchor" id="line-130"></span></p><p class="line874">Although I don’t really want to say that there’s a “correct” answer about which effect size to use, I will say that if you choose to compute d_z, d_r, or anything other than classical Cohen’s d, just please do not call it Cohen’s d. If you think these other effect sizes are useful, fine, but they are not the d statistic defined by Cohen! This kind of mislabeling is how we’ve ended up with 5 different ways of computing “Cohen’s d” for within-subjects designs. <span class="anchor" id="line-131"></span><span class="anchor" id="line-132"></span></p><p class="line874">Finally, there is a serious discussion to be had about whether it is a good idea to routinely summarize results in terms of Cohen’s d or other standardized effect sizes at all, even in less complicated cases such as simple between-subjects designs. Thom Baguley has a nice paper with some thoughtful criticism of standardized effect sizes, and Jan Vanhove has written a couple of nice blog posts about it. Even Tukey seemed dissatisfied with the enterprise. In my opinion, standardized effect sizes are generally a bad idea for data summary and meta-analytic purposes. It’s hard to imagine a cumulative science built on standardized effect sizes, rather than on effects expressed in terms of psychologically meaningful units. With that said, I do think standardized effect sizes can be useful for doing power analysis or for defining reasonably informative priors when you don’t have previous experimental data. <span class="anchor" id="line-133"></span><span class="anchor" id="line-134"></span></p><p class="line874">Footnotes <span class="anchor" id="line-135"></span><span class="anchor" id="line-136"></span></p><p class="line874">1 In general, this is really a weighted sum where the variance components due to random slopes must be multiplied by a term that depends on the contrast codes that were used. Because I used contrast codes of -1 and +1, it works out to simply be the sum of the variance components here, which is precisely why I changed the default contrasts before fitting the mixed model. But be aware that for other contrast codes, it won’t simply be the sum of the variance components. For more info, see pp. 20-21 of my dissertation. <span class="anchor" id="line-137"></span><span class="anchor" id="line-138"></span></p><p class="line874">2 If you actually compute classical Cohen’s d using the square root of the sum of the estimated variance components, you will find that there is a very slight numerical difference between this and the way we computed d in the earlier section (0.2498 vs. 0.2504). These two computations are technically slightly different, although they estimate the same quantity and should be asymptotically equivalent. In practice the numerical differences are negligible, and it is usually easier to compute d the previous way, that is, without having to fit a mixed model. <span class="anchor" id="line-139"></span><span class="anchor" id="bottom"></span></p></div><p id="pageinfo" class="info" lang="en" dir="ltr">None: FAQ/tdunpaired  (last edited 2017-06-05 14:41:57 by <span title="PeterWatson @ pc0021.mrc-cbu.cam.ac.uk[172.31.10.21]"><a class="interwiki" href="http://wiki.mrc-cbu.cam.ac.uk/basewiki/PeterWatson" title="PeterWatson @ pc0021.mrc-cbu.cam.ac.uk[172.31.10.21]">PeterWatson</a></span>)</p>

<div id="pagebottom"></div>
</div>

<div id="footer"><div id="footercredits">
<ul id="credits">
<li><a href="http://moinmo.in/" title="This site uses the MoinMoin Wiki software.">MoinMoin Powered</a></li><li><a href="http://moinmo.in/Python" title="MoinMoin is written in Python.">Python Powered</a></li><li><a href="http://moinmo.in/GPL" title="MoinMoin is GPL licensed.">GPL licensed</a></li><li><a href="http://validator.w3.org/check?uri=referer" title="Click here to validate this page.">Valid HTML 4.01</a></li>
</ul>


</div>
<div id="footercustom">(c) MRC Cognition and Brain Sciences Unit 2009 &nbsp; &nbsp;</div>
</div>
</div>



<deepl-input-controller><template shadowrootmode="open"><link rel="stylesheet" href="chrome-extension://cofdbpoegempjloogbagkncekinflcnj/build/content.css"><div><div class="dl-input-translation-container svelte-ju4595"><div></div></div></div></template></deepl-input-controller></body></html>